
# coding: utf-8

# # Training a VAE to the MNIST dataset
# We want to create a VAE which represents the images in the MNIST dataset. This serves as a practice for VAEs in theory and their relative tensorflow implementation.
# At the end, we will present some generated samples for comparison.

# In[86]:


import mnist, scipy
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tnrange


# Now we need to import the train set of the MNIST dataset. A this point, we do not care for the testset. The testset could be used, for example, to test a classifier based on the hidden vector generated by the VAE. We also do not care about the labels now, since this is an unsupervised approach.

# In[7]:


images = mnist.train_images()
images = images / 256


# In[14]:


plt.imshow(images[42])
plt.show()


# ## Defining the AE
# Now we want to define the structure of the AE using TF. The AE has 2 main components:
# - Encoder: convolutional layers
# - Decoder: deconvolutional layers
# The specific distribution we want in a VAE is enforced by the loss we define. We want the encoder to output mean and standard deviations of a fixed number of distributions (which we want to be normal gaussians)

# In[146]:


BATCH_SIZE = 64
LATENT_SIZE = 10
LEARNING_RATE = 0.0005

tf.reset_default_graph()

# Input image
X = tf.placeholder(dtype=tf.float32, shape=(None, 28, 28))
# Reshape for convolution
X4d = tf.reshape(X, shape=(-1, 28, 28, 1))
# Dropout keep proba
keep_prob = tf.placeholder(dtype=tf.float32, shape=(), name='keep_prob')

# ENCODER GRAPH
with tf.variable_scope("encoder", reuse=None):
    conv1 = tf.layers.conv2d(X4d, filters=64, kernel_size=4, strides=2, padding='same', activation=tf.nn.relu)
    drop1 = tf.nn.dropout(conv1, keep_prob)
    conv2 = tf.layers.conv2d(drop1, filters=64, kernel_size=4, strides=2, padding='same', activation=tf.nn.relu)
    drop2 = tf.nn.dropout(conv2, keep_prob)
    conv3 = tf.layers.conv2d(drop2, filters=64, kernel_size=4, strides=1, padding='same', activation=tf.nn.relu)
    drop3 = tf.nn.dropout(conv3, keep_prob)
    flat = tf.layers.flatten(drop3)
    latent_means = tf.layers.dense(flat, units=LATENT_SIZE)
    latent_std = tf.layers.dense(flat, units=LATENT_SIZE)
    latent_noise = tf.random_normal(shape=(BATCH_SIZE, LATENT_SIZE))
    latent_vector = latent_means + tf.multiply(latent_std, latent_noise)

# DECODER GRAPH
with tf.variable_scope("decoder", reuse=None):
    deflat = tf.layers.dense(latent_vector, units=flat.shape[1])
    deflat4d = tf.reshape(deflat, shape=(-1, drop3.shape[1], drop3.shape[2], drop3.shape[3]))
    deconv1 = tf.layers.conv2d_transpose(deflat4d, filters=64, kernel_size=4, strides=1, padding='same', activation=tf.nn.relu)
    dedrop1 = tf.nn.dropout(deconv1, keep_prob)
    deconv2 = tf.layers.conv2d_transpose(dedrop1, filters=64, kernel_size=4, strides=2, padding='same', activation=tf.nn.relu)
    dedrop2 = tf.nn.dropout(deconv2, keep_prob)
    deconv3 = tf.layers.conv2d_transpose(dedrop2, filters=1, kernel_size=4, strides=2, padding='same', activation=tf.nn.relu)
    dedrop3 = tf.nn.dropout(deconv3, keep_prob)
    rebuild = tf.reshape(dedrop3, shape=(-1, 28, 28))
    
# Loss
reconstruction_loss = tf.reduce_sum(tf.squared_difference(rebuild, X))
reg_loss = tf.reduce_sum(-tf.log(tf.abs(latent_std)) + 0.5 * (tf.square(latent_std) + tf.square(latent_means) - 1))
complete_loss = reconstruction_loss + reg_loss

# Optimizer
optimizer = tf.train.AdamOptimizer(LEARNING_RATE).minimize(complete_loss)


# In[147]:


sess = tf.Session()
sess.run(tf.global_variables_initializer())


# Once we have declared the network structure and initialized it, we can begin the training procedure.

# In[148]:


# Training
N_EPOCHS = 200
for epoch in tnrange(N_EPOCHS):
    losses = []
    for bindex in range(0, 16384, BATCH_SIZE):
        batch = images[bindex:bindex+BATCH_SIZE]
        _loss, _ = sess.run([complete_loss, optimizer], feed_dict = {X: batch, keep_prob:0.8})
        losses.append(_loss)
    print("Epoch", epoch, "- Mean Loss:", np.mean(losses))


# Now we can generate random samples by feeding a noise vector, distributed as a standard normal.

# In[149]:


R, C = 8, 8
z = np.random.standard_normal((R*C, LATENT_SIZE))
reco = sess.run(rebuild, feed_dict = {latent_vector: z, keep_prob:1.0})
f, ax = plt.subplots(R, C, figsize=(16,16))
for r in range(R):
    for c in range(C):
        ax[r,c].imshow(reco[r*8 + c])
plt.show()


# The results are quite good, keeping also in mind that this was not tuned and serves only as a proof of concept and bug-testing.
